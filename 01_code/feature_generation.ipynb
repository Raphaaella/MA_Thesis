{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e826ec",
   "metadata": {},
   "source": [
    "# Domain Classification and GNN Feature Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd3497",
   "metadata": {},
   "source": [
    "This notebook preprocesses data to prepare node features and edges for a GNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd33d99",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "article_embeddings = pd.read_csv('article_embeddings.csv')\n",
    "url_domains = pd.read_csv('url_domains.csv')\n",
    "chats = pd.read_csv('chats.csv')\n",
    "chat_url_shares = load_npz('chat_url_shares.npz')  # Sparse matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5e60b",
   "metadata": {},
   "source": [
    "## Step 2: Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383414ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align URLs and domains\n",
    "article_embeddings = article_embeddings.merge(url_domains[['url', 'domain', 'virality', 'year', 'pc1']], on='url', how='inner')\n",
    "\n",
    "# Group by domain and average article embeddings\n",
    "article_embeddings['article_embedding'] = article_embeddings['article_embedding'].apply(eval)  # Convert string to list\n",
    "article_embeddings_grouped = (\n",
    "    article_embeddings.groupby('domain')['article_embedding']\n",
    "    .apply(lambda x: np.mean(x.tolist(), axis=0))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add other domain-level features\n",
    "domain_features = (\n",
    "    url_domains[['domain', 'virality', 'year', 'pc1']]\n",
    "    .drop_duplicates()\n",
    "    .merge(article_embeddings_grouped, on='domain', how='inner')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c27298",
   "metadata": {},
   "source": [
    "## Step 3: Compute Domain-Level Chat Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_counts = chat_url_shares.sum(axis=0).A1  # Total shares per URL\n",
    "url_domains['total_chat_shares'] = chat_counts\n",
    "\n",
    "# Aggregate per domain\n",
    "domain_chat_stats = (\n",
    "    url_domains.groupby('domain')['total_chat_shares']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge with domain features\n",
    "domain_features = domain_features.merge(domain_chat_stats, on='domain', how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ee655",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chats, test_chats = train_test_split(chats['id'], test_size=0.2, random_state=42)\n",
    "\n",
    "def assign_split(chat_url_shares, train_chats, test_chats):\n",
    "    train_indices = train_chats.to_list()\n",
    "    test_indices = test_chats.to_list()\n",
    "    \n",
    "    train_urls = set()\n",
    "    test_urls = set()\n",
    "    \n",
    "    for chat_idx, url_idx in zip(*chat_url_shares.nonzero()):\n",
    "        if chat_idx in train_indices:\n",
    "            train_urls.add(url_idx)\n",
    "        elif chat_idx in test_indices:\n",
    "            test_urls.add(url_idx)\n",
    "\n",
    "    return train_urls, test_urls\n",
    "\n",
    "train_urls, test_urls = assign_split(chat_url_shares, train_chats, test_chats)\n",
    "\n",
    "train_features = domain_features[domain_features['domain'].isin(train_urls)]\n",
    "test_features = domain_features[domain_features['domain'].isin(test_urls)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad4063",
   "metadata": {},
   "source": [
    "## Step 5: Prepare GNN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = chat_url_shares.nonzero()\n",
    "edges = defaultdict(int)\n",
    "\n",
    "for row, col in zip(rows, cols):\n",
    "    domain_a = url_domains.iloc[row]['domain']\n",
    "    domain_b = url_domains.iloc[col]['domain']\n",
    "    if domain_a != domain_b:\n",
    "        edges[(domain_a, domain_b)] += chat_url_shares[row, col]\n",
    "\n",
    "edge_list = pd.DataFrame(\n",
    "    [(source, target, weight) for (source, target), weight in edges.items()],\n",
    "    columns=['source', 'target', 'weight']\n",
    ")\n",
    "\n",
    "train_features.to_csv('train_features.csv', index=False)\n",
    "test_features.to_csv('test_features.csv', index=False)\n",
    "edge_list.to_csv('edges.csv', index=False)\n",
    "\n",
    "print(\"Preprocessing complete. Train/Test features and edges saved.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
