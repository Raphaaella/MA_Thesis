{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bipartite Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raphaela\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Raphaela/Documents/MA_Studium/4_Semester/MA_Thesis/02_data/url_titles_domains.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5195 entries, 0 to 5194\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               5195 non-null   int64  \n",
      " 1   url              5195 non-null   object \n",
      " 2   start_date       5195 non-null   object \n",
      " 3   end_date         5195 non-null   object \n",
      " 4   title            5195 non-null   object \n",
      " 5   domain           5195 non-null   object \n",
      " 6   pc1              5195 non-null   float64\n",
      " 7   chat_idx         5195 non-null   int64  \n",
      " 8   start_year       5195 non-null   int64  \n",
      " 9   start_month      5195 non-null   int64  \n",
      " 10  start_day        5195 non-null   int64  \n",
      " 11  start_hour       5195 non-null   int64  \n",
      " 12  title_embedding  5195 non-null   object \n",
      "dtypes: float64(1), int64(6), object(6)\n",
      "memory usage: 527.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "     ---------------------------------------- 0.0/63.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 63.1/63.1 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting aiohttp (from torch_geometric)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (2024.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (2.1.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: requests in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (4.66.5)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch_geometric)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->torch_geometric)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "     ---------------------------------------- 0.0/65.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.8/65.8 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch_geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch_geometric) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\raphaela\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.2/1.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.1 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.7/1.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.6 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 317.4/381.6 kB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 381.6/381.6 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.6/51.6 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "   ---------------------------------------- 0.0/89.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 89.6/89.6 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: propcache, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch_geometric\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.0 torch_geometric-2.6.1 yarl-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Raphaela\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by 'domain' and 'chat_idx'\n",
    "grouped_data = df.groupby(['domain', 'chat_idx']).size().reset_index(name='count')\n",
    "\n",
    "# Step 2: Create a mapping for domains and chat_idx to numerical indices\n",
    "domain_mapping = {domain: i for i, domain in enumerate(grouped_data['domain'].unique())}\n",
    "chat_mapping = {chat: i for i, chat in enumerate(grouped_data['chat_idx'].unique())}\n",
    "\n",
    "# Step 3: Create the bipartite edge list\n",
    "row = grouped_data['domain'].map(domain_mapping).values\n",
    "col = grouped_data['chat_idx'].map(chat_mapping).values\n",
    "data = grouped_data['count'].values\n",
    "\n",
    "# Step 4: Create a sparse matrix for the bipartite graph\n",
    "bipartite_matrix = coo_matrix((data, (row, col)), shape=(len(domain_mapping), len(chat_mapping)))\n",
    "\n",
    "# Step 5: Convert the sparse matrix to a PyTorch Geometric data format\n",
    "edge_index, edge_weight = from_scipy_sparse_matrix(bipartite_matrix)\n",
    "# bipartite_graph = Data(edge_index=edge_index, edge_weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raphaela\\AppData\\Local\\Temp\\ipykernel_7208\\802309155.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pc1_values[:num_domains] = torch.tensor(df.groupby('domain')['pc1'].first().map(domain_mapping))\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare features\n",
    "num_domains = len(domain_mapping)\n",
    "num_chats = len(chat_mapping)\n",
    "\n",
    "# Example: Initialize node features randomly for simplicity\n",
    "domain_features = torch.rand(num_domains, 16)  # 16 is an arbitrary feature dimension\n",
    "chat_features = torch.rand(num_chats, 16)\n",
    "\n",
    "# Combine domain and chat features into a single tensor\n",
    "node_features = torch.cat([domain_features, chat_features], dim=0)\n",
    "\n",
    "# Step 2: Set up the target values (pc1) for domain nodes\n",
    "pc1_values = torch.zeros(num_domains + num_chats)\n",
    "pc1_values[:num_domains] = torch.tensor(df.groupby('domain')['pc1'].first().map(domain_mapping))\n",
    "\n",
    "# Step 3: Create the PyTorch Geometric data object\n",
    "bipartite_graph = Data(x=node_features, edge_index=edge_index, edge_weight=edge_weight, y=pc1_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the GNN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(16, 32)\n",
    "        self.conv2 = GCNConv(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First GCN layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "bipartite_graph = bipartite_graph.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m model(bipartite_graph)\n\u001b[1;32m----> 5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbipartite_graph\u001b[49m\u001b[43m]\u001b[49m, bipartite_graph\u001b[38;5;241m.\u001b[39my[bipartite_graph])\n\u001b[0;32m      6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\data\\data.py:577\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\data\\storage.py:118\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(bipartite_graph)\n",
    "    loss = criterion(out[bipartite_graph.train_mask], bipartite_graph.y[bipartite_graph.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "pred = model(bipartite_graph).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming num_domains is the number of domain nodes\n",
    "num_nodes = bipartite_graph.num_nodes\n",
    "num_nodes\n",
    "num_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(bipartite_graph.x).any(), \"Node features contain NaN\"\n",
    "assert not torch.isnan(bipartite_graph.y).any(), \"Target values contain NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartite_graph.y = torch.nan_to_num(bipartite_graph.x, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally normalize features\n",
    "bipartite_graph.x = (bipartite_graph.x - bipartite_graph.x.mean(dim=0)) / (bipartite_graph.x.std(dim=0) + 1e-6)\n",
    "\n",
    "# Set edge weights to 1 if they are not already set or if they are problematic\n",
    "bipartite_graph.edge_weight = torch.ones(bipartite_graph.edge_index.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN loss at epoch 1\n",
      "Test Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create train-test split indices\n",
    "train_size = int(0.8 * num_domains)  # Use 80% of the domain nodes for training\n",
    "indices = np.random.permutation(num_domains)\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "# Step 2: Create train and test masks\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "# Set the masks for the domain nodes\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "# Step 3: Add the masks to the bipartite_graph data object\n",
    "bipartite_graph.train_mask = train_mask\n",
    "bipartite_graph.test_mask = test_mask\n",
    "\n",
    "# Now you can proceed with training\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(bipartite_graph)\n",
    "    loss = criterion(out[bipartite_graph.train_mask], bipartite_graph.y[bipartite_graph.train_mask])\n",
    "\n",
    "    # Check if loss is NaN during training\n",
    "    if torch.isnan(loss):\n",
    "        print(f\"NaN loss at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "model.eval()\n",
    "pred = model(bipartite_graph).detach().cpu().numpy()\n",
    "test_loss = criterion(out[bipartite_graph.test_mask], bipartite_graph.y[bipartite_graph.test_mask])\n",
    "print(f'Test Loss: {test_loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
