{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c3eed6-fa9f-480a-b1e2-ace08e49d370",
   "metadata": {},
   "source": [
    "# Hierarchical GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7fadd91-4838-4dd4-aa47-6db9d333bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed filelock-3.17.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac65e9fb-b5e9-4e72-8834-d42a1d085e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (3.8.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (2023.9.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->torch_geometric) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->torch_geometric) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fb1a504-7bbf-4293-af16-001fa4fd8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.nn import HGTConv, GATConv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb55140-4eb6-4a41-a487-d06314efd807",
   "metadata": {},
   "source": [
    "## 01 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1eb5430d-54df-436b-8b05-7b91964ed5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = pd.read_csv('../02_data/train_test/train_edge_list.csv') #  0 \"chat_id\" int64, 1 \"domain_index\" object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7156948b-1724-4d80-ae0e-21c3746d3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validated Projected Bipartite Network\n",
    "edge_np = np.load(\"../02_data/train_test/validated_edges.npy\", allow_pickle=True)\n",
    "edge_nodes = set(edge_np.flatten()) \n",
    "\n",
    "# Convert edge list numpy array to DataFrame\n",
    "edge_df = pd.DataFrame(edge_np, columns=[\"chat_id\", \"domain_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5b9cbf44-20cf-435b-b875-a771a5af8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data = pd.read_csv('grouped_main_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7628f732-2400-470f-b7c7-cee7c245e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../02_data/train_test/train_data.csv')\n",
    "test_data = pd.read_csv('../02_data/train_test/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "686357ad-ad9c-4292-b4d7-db0ad4221400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_list info (train edges)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194454 entries, 0 to 194453\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype\n",
      "---  ------        --------------   -----\n",
      " 0   chat_id       194454 non-null  int64\n",
      " 1   domain_index  194454 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 3.0 MB\n",
      "None\n",
      "-------------------------------------------------\n",
      "chat_data info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49412 entries, 0 to 49411\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   id                 49412 non-null  int64         \n",
      " 1   name               49412 non-null  object        \n",
      " 2   type               49412 non-null  object        \n",
      " 3   db_index           49412 non-null  int64         \n",
      " 4   description        49411 non-null  object        \n",
      " 5   message_count      49412 non-null  float64       \n",
      " 6   total_view_count   49412 non-null  float64       \n",
      " 7   total_fwd_count    49412 non-null  float64       \n",
      " 8   oldest_post        20092 non-null  datetime64[ns]\n",
      " 9   clean_description  49279 non-null  object        \n",
      " 10  topic              49412 non-null  int64         \n",
      " 11  topic_probability  49412 non-null  float64       \n",
      " 12  topic_label        49412 non-null  object        \n",
      " 13  oldest_post_year   20092 non-null  Int64         \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "-------------------------------------------------\n",
      "train_data info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4753 entries, 0 to 4752\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   domain             4753 non-null   object \n",
      " 1   domain_index       4753 non-null   int64  \n",
      " 2   url_index          4753 non-null   int64  \n",
      " 3   article            4753 non-null   object \n",
      " 4   article_embedding  4753 non-null   object \n",
      " 5   virality           4753 non-null   float64\n",
      " 6   avalanches         4753 non-null   float64\n",
      " 7   messages           4753 non-null   float64\n",
      " 8   chats              4753 non-null   float64\n",
      " 9   year               4753 non-null   float64\n",
      " 10  pc1                4753 non-null   float64\n",
      " 11  label              4753 non-null   int64  \n",
      " 12  pc1_class          4753 non-null   int64  \n",
      "dtypes: float64(6), int64(4), object(3)\n",
      "memory usage: 482.9+ KB\n",
      "None\n",
      "-------------------------------------------------\n",
      "test_data info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1189 entries, 0 to 1188\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   domain             1189 non-null   object \n",
      " 1   domain_index       1189 non-null   int64  \n",
      " 2   url_index          1189 non-null   int64  \n",
      " 3   article            1189 non-null   object \n",
      " 4   article_embedding  1189 non-null   object \n",
      " 5   virality           1189 non-null   float64\n",
      " 6   avalanches         1189 non-null   float64\n",
      " 7   messages           1189 non-null   float64\n",
      " 8   chats              1189 non-null   float64\n",
      " 9   year               1189 non-null   float64\n",
      " 10  pc1                1189 non-null   float64\n",
      " 11  label              1189 non-null   int64  \n",
      "dtypes: float64(6), int64(3), object(3)\n",
      "memory usage: 111.6+ KB\n",
      "None\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"edge_list info (train edges)\")\n",
    "print(edge_df.info())\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"chat_data info\")\n",
    "print(chat_data.info())\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"train_data info\")\n",
    "print(train_data.info())\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "print(\"test_data info\")\n",
    "print(test_data.info())\n",
    "print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "30b8bd68-496b-4d5f-9a6c-4e675f971877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194454, 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb663d73-02db-40ad-b1e3-bb525ce02b9d",
   "metadata": {},
   "source": [
    "## 02 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d7e2fd29-f229-45e1-b5f9-75412f52549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered edge list shape: (46699, 2)\n"
     ]
    }
   ],
   "source": [
    "# Keep only valid edges\n",
    "filtered_edge_df = edge_df[\n",
    "    edge_df[\"chat_id\"].isin(chat_ids) & edge_df[\"domain_index\"].isin(domain_indices)\n",
    "]\n",
    "edge_np = filtered_edge_df.to_numpy()\n",
    "print(f\"Filtered edge list shape: {edge_np.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0f1e25df-2635-4b21-8067-128878e50be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chats: 1103\n",
      "domains: 3024\n"
     ]
    }
   ],
   "source": [
    "# Remap chat_id and domain_index to a 0-based index\n",
    "unique_chat_ids = np.unique(edge_np[:, 0])\n",
    "unique_domain_ids = np.unique(edge_np[:, 1])\n",
    "\n",
    "print(\"chats:\", len(unique_chat_ids))\n",
    "print(\"domains:\", len(unique_domain_ids))\n",
    "\n",
    "# Create mapping dictionaries\n",
    "chat_id_map = {old_id: new_id for new_id, old_id in enumerate(unique_chat_ids)}\n",
    "domain_id_map = {old_id: new_id for new_id, old_id in enumerate(unique_domain_ids)}\n",
    "\n",
    "# Apply mapping\n",
    "edge_np[:, 0] = np.vectorize(chat_id_map.get)(edge_np[:, 0])\n",
    "edge_np[:, 1] = np.vectorize(domain_id_map.get)(edge_np[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "94d5eb6f-4c62-47cc-9cf4-11c95e4f7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data[\"oldest_post\"] = pd.to_datetime(chat_data[\"oldest_post\"], errors=\"coerce\")\n",
    "\n",
    "# Extract year\n",
    "chat_data[\"oldest_post_year\"] = chat_data[\"oldest_post\"].dt.year.astype(\"Int64\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "49d48602-419e-46d4-95d0-32d1cfe0cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize pc1\n",
    "train_data[\"pc1_class\"] = np.digitize(train_data[\"pc1\"], bins=[0.33, 0.66])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_data[['virality', 'avalanches', 'messages', 'year']])\n",
    "chat_features = scaler.fit_transform(chat_data[['message_count', 'total_view_count', 'oldest_post_year', 'topic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b9d17328-c656-4fd6-8656-313f63f466b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03910525, -0.04284129,  1.42687227, -0.72738467],\n",
       "       [-0.03974649, -0.04651106,  0.68244295,  3.73440883],\n",
       "       [-0.03860651, -0.0456818 ,  0.68244295, -0.72738467],\n",
       "       ...,\n",
       "       [-0.04052232, -0.04693159,         nan, -0.28120532],\n",
       "       [-0.01308353,  0.06827296,         nan, -0.72738467],\n",
       "       [-0.04052232, -0.04693159,         nan, -0.72738467]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fb6c3e40-f978-4221-900d-b0b219d76940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "train_x = torch.tensor(train_features, dtype=torch.float)\n",
    "chat_x = torch.tensor(chat_features, dtype=torch.float)\n",
    "y = torch.tensor(train_data[\"pc1_class\"].values, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "edge_index = torch.tensor(edge_np.T, dtype=torch.long)\n",
    "\n",
    "# Define Heterogeneous Graph Data\n",
    "data = HeteroData()\n",
    "data['chat'].x = chat_x\n",
    "data['domain'].x = train_x\n",
    "data['domain'].y = y\n",
    "\n",
    "# Define edges\n",
    "data['chat', 'interacts', 'domain'].edge_index = edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "23253453-bd86-4374-b812-da8f7fdba799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 46699])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4882a6d6-0f35-43c0-b78a-db79f146ddca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  chat={ x=[49412, 4] },\n",
       "  domain={\n",
       "    x=[4753, 4],\n",
       "    y=[4753],\n",
       "  },\n",
       "  (chat, interacts, domain)={ edge_index=[2, 46699] }\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cbea287d-46b4-461c-9f51-654e10173ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node types in data: ['chat', 'domain']\n"
     ]
    }
   ],
   "source": [
    "print(\"Node types in data:\", data.node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1dddbf5f-0a80-427a-9af3-ba27cb865766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available x_dict keys: dict_keys(['chat', 'domain'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Available x_dict keys:\", data.x_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "50a86770-e0d7-4db7-87b9-59c098b4b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat feature size: torch.Size([49412, 4])\n",
      "Domain feature size: torch.Size([4753, 4])\n",
      "Max chat_id in edge_list: 1103\n",
      "Max domain_index in edge_list: 3024\n",
      "Max chat_id in chat_data: 64981\n",
      "Max domain_index in train_data: 5941\n"
     ]
    }
   ],
   "source": [
    "print(f\"Chat feature size: {data['chat'].x.shape}\")\n",
    "print(f\"Domain feature size: {data['domain'].x.shape}\")\n",
    "\n",
    "print(f\"Max chat_id in edge_list: {len(unique_chat_ids)}\")\n",
    "print(f\"Max domain_index in edge_list: {len(unique_domain_ids)}\")\n",
    "\n",
    "print(f\"Max chat_id in chat_data: {chat_data['id'].max()}\")\n",
    "print(f\"Max domain_index in train_data: {train_data['domain_index'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c664c03-b5c1-4224-b5aa-50d17856df59",
   "metadata": {},
   "source": [
    "## 03 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0e73a39a-7472-4853-b32c-7bf222bd7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b7d402cf-259a-4979-91cb-79ffed6617f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.chat_proj = Linear(data.x_dict['chat'].shape[1], hidden_dim)\n",
    "        self.domain_proj = Linear(data.x_dict['domain'].shape[1], hidden_dim)\n",
    "\n",
    "        self.conv1 = HGTConv(hidden_dim, hidden_dim, data.metadata()) \n",
    "        self.conv2 = HGTConv(hidden_dim, hidden_dim, data.metadata()) \n",
    "\n",
    "        self.fc = Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        print(\"Available node types:\", data.node_types)\n",
    "        print(\"Available x_dict keys before projection:\", data.x_dict.keys())\n",
    "\n",
    "        if 'chat' not in data.x_dict:\n",
    "            raise ValueError(\"❌ 'chat' node type is missing from x_dict! Ensure it's properly assigned.\")\n",
    "\n",
    "        # Initial projection\n",
    "        data.x_dict['chat'] = self.chat_proj(data.x_dict['chat'])\n",
    "        data.x_dict['domain'] = self.domain_proj(data.x_dict['domain'])\n",
    "\n",
    "        print(\"Available x_dict keys after projection:\", data.x_dict.keys())\n",
    "\n",
    "        # Hierarchical message passing\n",
    "        conv1_out = self.conv1(data.x_dict, data.edge_index_dict)\n",
    "        print(\"conv1 output keys:\", conv1_out.keys())  # Debugging step\n",
    "\n",
    "        if 'chat' not in conv1_out:\n",
    "            raise ValueError(\"❌ 'chat' is missing in conv1 output! Check HGTConv input.\")\n",
    "\n",
    "        data.x_dict['chat'] = F.relu(conv1_out['chat'])\n",
    "\n",
    "        conv2_out = self.conv2(data.x_dict, data.edge_index_dict)\n",
    "        print(\"conv2 output keys:\", conv2_out.keys())  # Debugging step\n",
    "\n",
    "        if 'domain' not in conv2_out:\n",
    "            raise ValueError(\"❌ 'domain' is missing in conv2 output! Check HGTConv input.\")\n",
    "\n",
    "        data.x_dict['domain'] = F.relu(conv2_out['domain'])\n",
    "\n",
    "        # Classification layer\n",
    "        out = global_mean_pool(data.x_dict['domain'], torch.arange(data['domain'].num_nodes))\n",
    "        return F.log_softmax(self.fc(out), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "54407119-1344-401d-bfc3-c0c140cf21f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available node types: ['chat', 'domain']\n",
      "Available x_dict keys: dict_keys(['chat', 'domain'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train for 50 epochs\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[171], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[158], line 28\u001b[0m, in \u001b[0;36mHGNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     25\u001b[0m data\u001b[38;5;241m.\u001b[39mx_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain_proj(data\u001b[38;5;241m.\u001b[39mx_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Hierarchical message passing\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m data\u001b[38;5;241m.\u001b[39mx_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     29\u001b[0m data\u001b[38;5;241m.\u001b[39mx_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(data\u001b[38;5;241m.\u001b[39mx_dict, data\u001b[38;5;241m.\u001b[39medge_index_dict)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Classification layer\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'chat'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# Training Loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data['domain'].y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Train for 50 epochs\n",
    "for epoch in range(50):\n",
    "    loss = train()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5c4ad425-4672-4bb9-84d5-2861742a9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['chat', 'domain'])\n",
      "dict_keys([('chat', 'interacts', 'domain')])\n"
     ]
    }
   ],
   "source": [
    "print(data.x_dict.keys())  # Should include 'chat' and 'domain'\n",
    "print(data.edge_index_dict.keys())  # Should match data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "09af403f-180e-413b-b4e9-f37281677ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['chat', 'domain'], [('chat', 'interacts', 'domain')])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5e9fb27c-3a5f-490e-b9c5-b9ab98f90ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure bidirectional edges\n",
    "data.edge_index_dict[('domain', 'interacts', 'chat')] = torch.flip(data.edge_index_dict[('chat', 'interacts', 'domain')], dims=[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e0470-12ba-48ad-97c8-8e7d4d8a0050",
   "metadata": {},
   "source": [
    "# 04 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c06207-721a-4814-a4ae-550f7f4d6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        acc = (pred == data['domain'].y).sum().item() / data['domain'].y.size(0)\n",
    "        print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
